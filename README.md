# tomasz-ai-blog
Just a place where I put my thoughts and notes on AI (reverse chronological order).

## (Draft) Deductive AI v 0.0.1 (4-7-24)

The answer to deductive AI might be in category theory. Let's start by simply teaching an agent to construct math. We will provide it some axioms and have it learn to deduce from the axioms various things. We'd likely have to construct a model from scratch, as I am paranoid that using some open source model will just regurgitate some memorized BS about math and make me think it's deducing, when in fact it's simply repeating what it's memorized... 

Currently researching 
1. category theory
2. graphs... directed graphs, especially. as they relate to graph neural nets...

## Stop Brute Force AI (4-7-24)


I did my undergrad in Applied Math. One of the most beautiful thing about math is the elegance of proofs. In math, we don't like to prove things "brute force"... even though that's technically a valid proof. We like to deductively, step-by-step, compose a proof.

I see the same problem today in deep learning. 

Throw more data at the problem.

Throw more compute at it, too.

Yes, we get better models. GPT4 > GPT3 > GPT2 and whatnot...

In a recent interview that I am not able to source, one of the guests mentioned Tesla is essentially just having their AI memorize every road, every possibile occurrence that could happen on the road, in order to get to Full Self Driving...

This may work for big companies, with tons of cash, just as brute force proofs technically do work...

But some tasks that we want to implement AI into will not have the amount of data we need to solve problems in a brute force way...

It'll be one of my goals to create systems that operate more elegantly. Like the human brain. 1,000,000x less memory, 1,000,000x less compute than the best LLM... 

Yet more powerful... yet able to deduce effectively... yet able to come up with novel ideas...

Is the way to get to AGI via throwing endless compute and data at it?

My math brain says no.
